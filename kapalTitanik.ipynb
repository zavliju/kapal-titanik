{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=r'C:\\Users\\Zavli\\Desktop\\train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path=r'C:\\Users\\Zavli\\Desktop\\test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import  SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd = sc.textFile(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rdd = sc.textFile(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked',\n",
       " '1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S',\n",
       " '2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C',\n",
       " '3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S',\n",
       " '4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked',\n",
       " '892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q',\n",
       " '893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S',\n",
       " '894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q',\n",
       " '895,3,\"Wirz, Mr. Albert\",male,27,0,0,315154,8.6625,,S']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTrain(rdd):\n",
    "\n",
    "    # ekstrak data header (row satu)\n",
    "    header = rdd.first()\n",
    "    # remove header\n",
    "    body = rdd.filter(lambda r: r!=header)\n",
    "    \n",
    "    # fungsi untuk Parse RDD ke DataFrame\n",
    "    def parseRow(row):\n",
    "        # remove double quote, split teks row dengan comma\n",
    "        row_list = row.replace('\"','').split(\",\")\n",
    "        # konversi python list ke tuple, yang kompetibel dengan struktur data pyspark \n",
    "        row_tuple = tuple(row_list)\n",
    "        return row_tuple\n",
    "\n",
    "    rdd_parsed = body.map(parseRow)\n",
    "\n",
    "    colnames = header.split(\",\")\n",
    "    colnames.insert(3,'FirstName')\n",
    "\n",
    "    return rdd_parsed.toDF(colnames)\n",
    "\n",
    "def parseTest(rdd):\n",
    "    header = rdd.first()\n",
    "    body = rdd.filter(lambda r: r!=header)\n",
    "\n",
    "    def parseRow(row):\n",
    "        row_list = row.replace('\"','').split(\",\")\n",
    "        row_tuple = tuple(row_list)\n",
    "        return row_tuple\n",
    "\n",
    "    rdd_parsed = body.map(parseRow)\n",
    "    \n",
    "    colnames = header.split(\",\")\n",
    "    colnames.insert(2,'FirstName')\n",
    "\n",
    "    return rdd_parsed.toDF(colnames)\n",
    "\n",
    "train_df = parseTrain(train_rdd)\n",
    "test_df = parseTest(test_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|FirstName|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|   Braund|     Mr. Owen Harris|  male| 22|    1|    0|       A/5 21171|   7.25|     |       S|\n",
      "|          2|       1|     1|  Cumings| Mrs. John Bradle...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen|         Miss. Laina|female| 26|    0|    0|STON/O2. 3101282|  7.925|     |       S|\n",
      "+-----------+--------+------+---------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add kolom survived ke data test \n",
    "train_df = train_df.withColumn('Mark',lit('train'))\n",
    "test_df = (test_df.withColumn('Survived',lit(0))\n",
    "                  .withColumn('Mark',lit('test')))\n",
    "test_df = test_df[train_df.columns]\n",
    "## Append data test ke data train \n",
    "df = train_df.unionAll(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[PassengerId: string, Survived: string, Pclass: string, FirstName: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string, Mark: string]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+---------+--------------------+------+----+-----+-----+-------+-------+-----+--------+----+\n",
      "|PassengerId|Survived|Pclass|FirstName|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|Mark|\n",
      "+-----------+--------+------+---------+--------------------+------+----+-----+-----+-------+-------+-----+--------+----+\n",
      "|        892|       0|     3|    Kelly|           Mr. James|  male|34.5|    0|    0| 330911| 7.8292|     |       Q|test|\n",
      "|        893|       0|     3|   Wilkes| Mrs. James (Elle...|female|  47|    1|    0| 363272|      7|     |       S|test|\n",
      "|        894|       0|     2|    Myles|  Mr. Thomas Francis|  male|  62|    0|    0| 240276| 9.6875|     |       Q|test|\n",
      "|        895|       0|     3|     Wirz|          Mr. Albert|  male|  27|    0|    0| 315154| 8.6625|     |       S|test|\n",
      "|        896|       0|     3| Hirvonen| Mrs. Alexander (...|female|  22|    1|    1|3101298|12.2875|     |       S|test|\n",
      "|        897|       0|     3| Svensson|    Mr. Johan Cervin|  male|  14|    0|    0|   7538|  9.225|     |       S|test|\n",
      "|        898|       0|     3| Connolly|          Miss. Kate|female|  30|    0|    0| 330972| 7.6292|     |       Q|test|\n",
      "+-----------+--------+------+---------+--------------------+------+----+-----+-----+-------+-------+-----+--------+----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: double (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: double (nullable = true)\n",
      " |-- Parch: double (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Mark: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Data Cleaning/Manipulation\n",
    "## konversi tipe data Age, SibSp, Parch, Fare ke double\n",
    "df = (df.withColumn('Age',df['Age'].cast(\"double\"))\n",
    "\t\t\t.withColumn('SibSp',df['SibSp'].cast(\"double\"))\n",
    "\t\t\t.withColumn('Parch',df['Parch'].cast(\"double\"))\n",
    "\t\t\t.withColumn('Fare',df['Fare'].cast(\"double\"))\n",
    "\t\t\t.withColumn('Survived',df['Survived'].cast(\"double\"))\n",
    "\t\t\t)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute missing Age dan Fare\n",
    "numVars = ['Survived','Age','SibSp','Parch','Fare']\n",
    "def missingAge(df):\n",
    " \n",
    "    def countNull(df, variable):\n",
    "        return df.where(df[variable].isNull()).count()\n",
    " \n",
    "    missingVAriable = {variable: countNull(df, variable) for variable in numVars}\n",
    "    mean_age = df.groupBy().mean('Age').first()[0]\n",
    "    mean_fare = df.groupBy().mean('Fare').first()[0]\n",
    "    df = df.na.fill({'Age': mean_age, 'Fare': mean_fare})\n",
    "    return df\n",
    " \n",
    "df = missingAge(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fungsi untuk mengekstrak title\n",
    "def extract_title(df):\n",
    "    getTitle = udf(lambda name: name.split('.')[0].strip(), StringType())\n",
    "    df = df.withColumn('Title', getTitle(df['Name']))\n",
    "    return df\n",
    " \n",
    "df = extract_title(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_category_to_int(df):\n",
    "    category = ['Pclass','Sex','Embarked']\n",
    "    si = StringIndexer(inputCol='Sex', outputCol='Sex_indexed')\n",
    "    df_indexed = si.fit(df).transform(df).drop('Sex').withColumnRenamed('Sex_indexed', 'Sex')\n",
    "    # menggunakan pipeline untuk mengindex semua kategori variabel\n",
    "    def indexer(df, col):\n",
    "        si = StringIndexer(inputCol=col, outputCol=col + '_indexed').fit(df)\n",
    "        return si\n",
    "    indexers = [indexer(df, col) for col in category]\n",
    "    pipeline = Pipeline(stages=indexers)\n",
    "    return pipeline.fit(df).transform(df)\n",
    " \n",
    "df = change_category_to_int(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors(df):\n",
    "    category = ['Pclass','Sex','Embarked']\n",
    "    category_index = [i+'_indexed' for i in category]\n",
    "    featuresCol = numVars + category_index\n",
    "    featuresCol.remove('Survived')\n",
    "    labelCol = ['Mark', 'Survived']\n",
    "    row = Row('mark', 'label', 'features')\n",
    "    df_indexed = df[labelCol + featuresCol]\n",
    "    # 0-mark, 1-label, 2-features\n",
    "    # map features ke DenseVector\n",
    "    lf = df_indexed.rdd.map(lambda r: (row(r[0], r[1], Vectors.dense(r[2:]), VectorUDT()))).toDF()\n",
    "    # index label\n",
    "    # mengonversi label numerik ke ketegori yang dibutuhkan untuk dt dan rf\n",
    "    lf = StringIndexer(inputCol='label', outputCol='index').fit(lf).transform(lf)\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = create_vectors(df)\n",
    "validate = 0\n",
    "def train_model(lf):\n",
    "    train = lf.where(lf.mark == 'train')\n",
    "    test = lf.where(lf.mark == 'test')\n",
    "    global validate\n",
    "    # random split yang untuk mendapakan train/validate\n",
    "    train, validate = train.randomSplit([0.7, 0.3], seed=121)\n",
    "    print ('Train Data: ' + str(train.count()))\n",
    "    print ('Validate Data: ' + str(validate.count()))\n",
    "    print ('Test Data: ' + str(test.count()))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------------+-----+\n",
      "| mark|label|            features|index|\n",
      "+-----+-----+--------------------+-----+\n",
      "|train|  0.0|[22.0,1.0,0.0,7.2...|  0.0|\n",
      "|train|  1.0|[38.0,1.0,0.0,71....|  1.0|\n",
      "|train|  1.0|[26.0,0.0,0.0,7.9...|  1.0|\n",
      "|train|  1.0|[35.0,1.0,0.0,53....|  1.0|\n",
      "|train|  0.0|[35.0,0.0,0.0,8.0...|  0.0|\n",
      "+-----+-----+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: 636\n",
      "Validate Data: 255\n",
      "Test Data: 418\n",
      "Train Data: 636\n",
      "Validate Data: 255\n",
      "Test Data: 418\n"
     ]
    }
   ],
   "source": [
    "train = train_model(lf)[0]\n",
    "test = train_model(lf)[1]\n",
    "# Logsitic Regression\n",
    "# regPara: regualrization parameter\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.05, labelCol='index').fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC: 0.8325267447784005\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan model evaluasi auc ROC(default buat binary classification)\n",
    "def test_model_regression(model, validate = validate):\n",
    "    pred = model.transform(validate)\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol='index')\n",
    "    return evaluator.evaluate(pred)\n",
    " \n",
    "print ('AUC ROC: ' + str(test_model_regression(lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DecistionTree': 0.7700267447784003, 'LogisticRegression': 0.8325267447784005, 'RandomForest': 0.8546867040244526}\n"
     ]
    }
   ],
   "source": [
    "# DT dan RF\n",
    "def dtRf():\n",
    "    dt = DecisionTreeClassifier(maxDepth=3, labelCol='index').fit(train)\n",
    "    rf = RandomForestClassifier(numTrees=100, labelCol='index').fit(train)\n",
    " \n",
    "    models = {'LogisticRegression': lr,\n",
    "              'DecistionTree': dt,\n",
    "              'RandomForest': rf}\n",
    " \n",
    "    modelPerf = {k: test_model_regression(v) for k, v in models.items()}\n",
    " \n",
    "    print (modelPerf)\n",
    " \n",
    "dtRf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
